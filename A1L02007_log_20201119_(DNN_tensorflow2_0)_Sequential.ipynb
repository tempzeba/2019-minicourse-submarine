{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1L02007_log_20201119 (DNN-tensorflow2.0)-Sequential.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOUNofCF/0p/cz/pE4a1tsL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tempzeba/2019-minicourse-submarine/blob/master/A1L02007_log_20201119_(DNN_tensorflow2_0)_Sequential.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y0w5q6AUmMa"
      },
      "source": [
        "## 0) 程式說明\n",
        "### 目的：A1L02007 IOT異常分析\n",
        "### 運行環境："
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhSdZF2NW8Xs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f36a05-e280-4e52-86d3-c2c0228483fd"
      },
      "source": [
        "import sys\n",
        "print(\"python版本:%s\"% sys.version)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "python版本:3.6.9 (default, Oct  8 2020, 12:12:24) \n",
            "[GCC 8.4.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIVId25Van3a"
      },
      "source": [
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('max_row',500)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5wddLSban3o"
      },
      "source": [
        "## 1) 載入資料集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-bjU2pan3p"
      },
      "source": [
        "# df_train = pd.read_csv('./data/Iris.csv')\n",
        "df_train = pd.read_csv('https://github.com/tempzeba/iot_test_public/releases/download/iot_data/A1L02007_log_01.csv', sep='\\t')\n",
        "df_train = df_train.drop(labels=[ \n",
        "r'收集日期',\n",
        "r'抽樣秒',\n",
        "r'位址區段B0紀錄時間',\n",
        "r'位址區段W10紀錄時間',\n",
        "r'位址區段W1200紀錄時間',\n",
        "r'位址區段W200紀錄時間',\n",
        "r'位址區段W2004紀錄時間'\n",
        ",\n",
        " 'A001. 空壓源SN#1異常',\n",
        " 'A010. 真空源SN#1異常',\n",
        " 'A020. EMO觸發異常',\n",
        " 'A030. CPU異常',\n",
        " 'A031. RD77MS16模組異常',\n",
        " 'A032. RS-485模組異常',\n",
        " 'A033. R64AD模組異常',\n",
        " 'A050. CPU電池 電力低下',\n",
        " 'A051. PLC保險絲燒毀',\n",
        " 'A052. PLC偵測 AC/DC 電力低下',\n",
        " 'A100. 轉塔伺服R軸異常',\n",
        " 'A101. 真空鼓R軸伺服異常',\n",
        " 'A102. 刀鼓R軸伺服異常',\n",
        " 'A103. 旋轉刀R軸伺服異常',\n",
        " 'A104. 轉瓶01伺服R軸異常',\n",
        " 'A105. 送標伺服R軸異常',\n",
        " 'A106. 螺桿01伺服R軸異常',\n",
        " 'A107. 膠鼓伺服R軸伺服異常',\n",
        " 'A108. 標捲A伺服R軸異常',\n",
        " 'A109. 標捲B伺服R軸異常',\n",
        " 'A110. 轉塔伺服Z軸異常',\n",
        " 'A111. 貼標主機伺服Z軸異常',\n",
        " 'A112. 貼標主機伺服Y軸異常',\n",
        " 'A113. 虛擬軸01伺服R軸異常',\n",
        " 'A114. 螺桿02伺服R軸異常',\n",
        " 'A115. 轉瓶02伺服R軸異常',\n",
        " 'A116. 轉瓶03伺服R軸異常',\n",
        " 'A117. 轉瓶04伺服R軸異常',\n",
        " 'A118. 轉瓶05伺服R軸異常',\n",
        " 'A119. 轉瓶06伺服R軸異常',\n",
        " 'A120. 轉瓶07伺服R軸異常',\n",
        " 'A121. 轉瓶08伺服R軸異常',\n",
        " 'A122. 轉瓶09伺服R軸異常',\n",
        " 'A123. 轉瓶10伺服R軸異常',\n",
        " 'A124. 轉瓶11伺服R軸異常',\n",
        " 'A125. 轉瓶12伺服R軸異常',\n",
        " 'A126. 轉瓶13伺服R軸異常',\n",
        " 'A127. 轉瓶14伺服R軸異常',\n",
        " 'A128. 轉瓶15伺服R軸異常',\n",
        " 'A129. 轉瓶16伺服R軸異常',\n",
        " 'A130. 轉瓶17伺服R軸異常',\n",
        " 'A131. 轉瓶18伺服R軸異常',\n",
        " 'A321. 操作側01門檢異常',\n",
        " 'A322. 操作側02門檢異常',\n",
        " 'A323. 維修側01門檢異常',\n",
        " 'A324. 維修側02門檢異常',\n",
        " 'A330.轉刀Index Sensor異常',\n",
        " 'A331.標籤MarkSensor異常',\n",
        " 'A340. 標籤斷標異常',\n",
        " 'A345. 張力位置不正確',\n",
        " 'A350. 入料星盤跳齒異常',\n",
        " 'A351. 出料星盤跳齒異常',\n",
        " 'A360. 真空標籤檢查異常',\n",
        " 'A361. 真空鼓沾膠標籤檢查異常',\n",
        " 'A362. 真空鼓漏貼標籤檢查異常',\n",
        " 'A364. 螺桿進瓶異常',\n",
        " 'A365. 進瓶甩瓶檢查異常',\n",
        " 'A366. 貼標甩瓶檢查異常',\n",
        " 'A367. 出瓶甩瓶檢查異常',\n",
        " 'A370. 倒瓶偵測異常',\n",
        " 'A371. 標籤切斷位置不正確',\n",
        " 'A380. Roll Fed變頻器異常',\n",
        " 'A381. Vacuum變頻器異常',\n",
        " 'A382. 膠泵變頻器異常',\n",
        " 'A383. 主輸送帶變頻器異常',\n",
        " 'A390. 膠鼓加熱器斷線異常',\n",
        " 'A391. 膠桶加熱器斷線異常',\n",
        " 'A392. 出膠板加熱器斷線異常',\n",
        " 'A393. 刮膠板加熱器斷線異常',\n",
        " 'A394. 盛料盤加熱器斷線異常',\n",
        " 'A395. 膠管加熱器斷線異常',\n",
        " 'A401. 轉塔伺服R軸未設原點',\n",
        " 'A402. 真空鼓伺服R軸未設原點',\n",
        " 'A403. 刀鼓伺服R軸未設原點',\n",
        " 'A404. 旋轉刀伺服R軸未設原點',\n",
        " 'A405. 轉瓶01伺服R軸未設原點',\n",
        " 'A406. 送標伺服R軸未設原點',\n",
        " 'A407. 螺桿01伺服R軸未設原點',\n",
        " 'A408. 膠鼓伺服R軸未設原點',\n",
        " 'A409. 標捲A伺服R軸未設原點',\n",
        " 'A410. 標捲B伺服R軸未設原點',\n",
        " 'A411. 轉塔伺服Z軸未設原點',\n",
        " 'A412. 貼標主機伺服Z軸未設原點',\n",
        " 'A413. 貼標主機伺服Y軸未設原點',\n",
        " 'A414. 虛擬軸01伺服R軸未設原點',\n",
        " 'A415. 螺桿02伺服R軸未設原點',\n",
        " 'A416. 轉瓶02伺服R軸未設原點',\n",
        " 'A417. 轉瓶03伺服R軸未設原點',\n",
        " 'A418. 轉瓶04伺服R軸未設原點',\n",
        " 'A419. 轉瓶05伺服R軸未設原點',\n",
        " 'A420. 轉瓶06伺服R軸未設原點',\n",
        " 'A421. 轉瓶07伺服R軸未設原點',\n",
        " 'A422. 轉瓶08伺服R軸未設原點',\n",
        " 'A423. 轉瓶09伺服R軸未設原點',\n",
        " 'A424. 轉瓶10伺服R軸未設原點',\n",
        " 'A425. 轉瓶11伺服R軸未設原點',\n",
        " 'A426. 轉瓶12伺服R軸未設原點',\n",
        " 'A427. 轉瓶13伺服R軸未設原點',\n",
        " 'A428. 轉瓶14伺服R軸未設原點',\n",
        " 'A429. 轉瓶15伺服R軸未設原點',\n",
        " 'A430. 轉瓶16伺服R軸未設原點',\n",
        " 'A431. 轉瓶17伺服R軸未設原點',\n",
        " 'A432. 轉瓶18伺服R軸未設原點',\n",
        " 'A455. 標簽長度設定錯誤',\n",
        " 'A456.ARC-Mark不正確',\n",
        " 'A460. 電控箱冷氣異常',\n",
        " '轉塔伺服R軸單元老化預警',\n",
        " '真空鼓伺服R軸單元老化預警',\n",
        " '刀鼓伺服R軸單元老化預警',\n",
        " '旋轉刀伺服R軸單元老化預警',\n",
        " '轉瓶01伺服R軸單元老化預警',\n",
        " '送標伺服R軸單元老化預警',\n",
        " '螺桿01伺服R軸單元老化預警',\n",
        " '膠鼓伺服R軸單元老化預警',\n",
        " '標捲A伺服R軸單元老化預警',\n",
        " '標捲B伺服R軸單元老化預警',\n",
        " '轉塔伺服Z軸單元老化預警',\n",
        " '貼標主機伺服Z軸單元老化預警',\n",
        " '貼標主機伺服Y軸單元老化預警',\n",
        " '保留軸單元老化預警',\n",
        " '螺桿02伺服R軸單元老化預警',\n",
        " '轉瓶02伺服R軸單元老化預警',\n",
        " '轉瓶03伺服R軸單元老化預警',\n",
        " '轉瓶04伺服R軸單元老化預警',\n",
        " '轉瓶05伺服R軸單元老化預警',\n",
        " '轉瓶06伺服R軸單元老化預警',\n",
        " '轉瓶07伺服R軸單元老化預警',\n",
        " '轉瓶08伺服R軸單元老化預警',\n",
        " '轉瓶09伺服R軸單元老化預警',\n",
        " '轉瓶10伺服R軸單元老化預警',\n",
        " '轉瓶11伺服R軸單元老化預警',\n",
        " '轉瓶12伺服R軸單元老化預警',\n",
        " '轉瓶13伺服R軸單元老化預警',\n",
        " '轉瓶14伺服R軸單元老化預警',\n",
        " '轉瓶15伺服R軸單元老化預警',\n",
        " '轉瓶16伺服R軸單元老化預警',\n",
        " '轉瓶17伺服R軸單元老化預警',\n",
        " '轉瓶18伺服R軸單元老化預警'\n",
        "\n",
        "],axis=1) \n",
        "\n",
        "df_train = df_train[df_train['ALife(PLC)']>=0]  #清除無效數據\n",
        "df_train.describe().transpose()\n",
        "# df_train.columns.to_list()\n",
        "\n",
        "\n",
        "a=sorted(list(df_train['故障代號'].unique()))\n",
        "\n",
        "label_map = dict(zip(a,range(len(a))))\n",
        "# print(label_map)\n",
        "\n",
        "df_train['故障序碼'] = df_train['故障代號'].map(label_map)\n",
        "# list(df_train['故障序碼'].unique())\n",
        "\n",
        "# 調整資料集\n",
        "# 1. 只取有異常部分\n",
        "# 2. 計算有異常資料筆數\n",
        "# 3. 從無異常資料隨機抽出k筆資料與異常資料合併作為投入模型的資料集。k=異常資料筆數\n",
        "mask = df_train[r'故障序碼'] > 0\n",
        "target_count = mask.sum()\n",
        "# print(target_count)\n",
        "df_train_noerr = df_train[df_train[r'故障序碼'] == 0].sample(n=target_count,random_state=123,axis=0)\n",
        "df_train = df_train[mask]\n",
        "df_train = df_train.append(df_train_noerr)\n",
        "# df_train.describe().transpose()"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1M7a4iian3u"
      },
      "source": [
        "## 2) 手動編碼\n",
        "處理名目資料 (Nominal variables) - 資料前處理\n",
        "依據特徵資料的特性，可以選擇手動編碼或自動編碼。\n",
        "\n",
        "### 使用編碼時機?\n",
        "進行深度學習時，神經網路只能處理數值資料。因此我們需要將所有非數字型態的特徵進行轉換。\n",
        "\n",
        "### 註：\n",
        "略。(IOT原始資料已經一次前處理)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txpEEPgAan36"
      },
      "source": [
        "## 3) 檢查缺失值\n",
        "使用 numpy 所提供的函式來檢查是否有 NA 缺失值，假設有缺失值使用dropna()來移除。使用的時機在於當只有少量的缺失值適用，若遇到有大量缺失值的情況，或是本身的資料量就很少的情況下建議可以透過機器學習的方法補值來預測缺失值。\n",
        "### 註：\n",
        "略。(IOT原始資料已經一次前處理)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNBeqTcUan4A"
      },
      "source": [
        "## 4) 將輸出特徵做one-hot encoding\n",
        "如何對欄位class做one-hot encoding？"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQFh4fj0an4C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61a075dc-ae72-46bd-cd1c-995420da12b7"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y = to_categorical(df_train[r'故障序碼'])\n",
        "y"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OclZM7Wan4I"
      },
      "source": [
        "## 5) 切割訓練集與測試集"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSw4NVQLwdvU"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjDEttMPan4J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e390e7b-96ec-4f90-c0aa-b566f8c74647"
      },
      "source": [
        "pd.set_option('max_row',500)\n",
        "# X=df_train.drop(labels=['Class'],axis=1)\n",
        "X=df_train.drop(columns=[r'故障序碼','故障代號'])\n",
        "# X.isna().sum().sum()\n",
        "# X\n",
        "mask = X.describe().transpose()['std']==0\n",
        "X.describe().transpose()[mask].index.tolist()\n",
        "# X.describe().transpose().columns.tolist()\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['初始化完成',\n",
              " 'No Alarm',\n",
              " '膠鼓設定溫度(SP)',\n",
              " '膠桶設定溫度(SP)',\n",
              " '出膠板設定溫度(SP)',\n",
              " '刮膠板設定溫度(SP)',\n",
              " '盛膠盤設定溫度(SP)',\n",
              " '送膠管設定溫度(SP)',\n",
              " '斷絲棒設定溫度(SP)',\n",
              " '現用瓶子高度',\n",
              " '現用瓶子直徑',\n",
              " '現用標籤寬度',\n",
              " '現用標籤厚度',\n",
              " '現用送標啟動補償值',\n",
              " '現用智能切標功能',\n",
              " '現用瓶型選擇',\n",
              " '現用轉瓶速度分子',\n",
              " '現用沾膠位置補償',\n",
              " '轉瓶貼標位置',\n",
              " 'Ax.002警報碼',\n",
              " 'Ax.003警報碼',\n",
              " 'Ax.005警報碼',\n",
              " 'Ax.006警報碼',\n",
              " 'Ax.008警報碼',\n",
              " 'Ax.010異常碼',\n",
              " 'Ax.011異常碼',\n",
              " 'Ax.011警報碼',\n",
              " 'Ax.012異常碼',\n",
              " 'Ax.012警報碼',\n",
              " 'Ax.013運轉速度0.01mm/Min',\n",
              " 'Ax.013異常碼',\n",
              " 'Ax.013警報碼',\n",
              " 'Ax.014異常碼',\n",
              " 'Ax.014扭力值(MD.104)',\n",
              " 'Ax.016警報碼',\n",
              " 'Ax.017警報碼',\n",
              " 'Ax.018警報碼',\n",
              " 'Ax.019警報碼',\n",
              " 'Ax.020警報碼',\n",
              " 'Ax.021警報碼',\n",
              " 'Ax.022警報碼',\n",
              " 'Ax.023警報碼',\n",
              " 'Ax.024警報碼',\n",
              " 'Ax.025警報碼',\n",
              " 'Ax.026警報碼',\n",
              " 'Ax.027警報碼',\n",
              " 'Ax.028警報碼',\n",
              " 'Ax.029警報碼',\n",
              " 'Ax.030警報碼',\n",
              " 'Ax.031警報碼',\n",
              " 'Ax.032警報碼']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKl7fICTan4Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train , X_test , y_train , y_test = train_test_split(X,y , test_size=.3 , random_state=40)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ovl96zhan4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22ba3f2b-c83d-4a12-cc4f-49745a725afc"
      },
      "source": [
        "print('訓練資料: ',X_train.shape)\n",
        "print('測試資料: ',X_test.shape)\n",
        "# X_train"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "訓練資料:  (1047, 231)\n",
            "測試資料:  (449, 231)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qB6zvYgJan4Z"
      },
      "source": [
        "## 6) 建立網路模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJvDPRx5an4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d08ae976-7d76-458b-c07f-f5a2b253d974"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q30p2WHxan4d"
      },
      "source": [
        "# 此範例使用 Tensorflow2.0 Sequential API 搭建神經網路。\n",
        "model = Sequential()\n",
        "model.add(Dense(8, Activation('relu'), input_dim=X.shape[-1]))\n",
        "model.add(Dense(16, Activation('relu')))\n",
        "model.add(Dense(17, Activation('softmax')))"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCfdh7Lgan4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1482996d-6da4-4371-f491-be0555a16412"
      },
      "source": [
        "model.summary()   # Weights = (4+1)*8+(8+1)*16+(16+1)*3"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_3 (Dense)              (None, 8)                 1856      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 16)                144       \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 17)                289       \n",
            "=================================================================\n",
            "Total params: 2,289\n",
            "Trainable params: 2,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "86S7ALLTan4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "656011d8-ad7f-49be-cd53-7bfe9cfd74fd"
      },
      "source": [
        "# 編譯模型\n",
        "optim = Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optim,\n",
        "              metrics=['acc'])\n",
        "\n",
        "batch_size=200\n",
        "epochs = 200\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    shuffle=True,\n",
        "                    validation_split=0.1)\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 0s 67ms/step - loss: 6592894.0000 - acc: 0.0180 - val_loss: 5178891.5000 - val_acc: 0.0381\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5050695.0000 - acc: 0.0287 - val_loss: 4044013.0000 - val_acc: 0.0571\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3881303.2500 - acc: 0.0499 - val_loss: 3245914.2500 - val_acc: 0.0952\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3052144.7500 - acc: 0.0945 - val_loss: 2654764.5000 - val_acc: 0.1238\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2453826.7500 - acc: 0.1359 - val_loss: 2195151.5000 - val_acc: 0.2381\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1998291.0000 - acc: 0.1815 - val_loss: 1818774.5000 - val_acc: 0.2476\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1639620.7500 - acc: 0.2208 - val_loss: 1496356.7500 - val_acc: 0.2571\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1339559.5000 - acc: 0.2505 - val_loss: 1237125.6250 - val_acc: 0.2667\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1101961.5000 - acc: 0.2909 - val_loss: 1028100.5000 - val_acc: 0.3333\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 905935.5000 - acc: 0.3057 - val_loss: 854570.0000 - val_acc: 0.3619\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 747309.5625 - acc: 0.3301 - val_loss: 713035.8750 - val_acc: 0.3524\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 614928.6250 - acc: 0.3365 - val_loss: 595639.8125 - val_acc: 0.3524\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 503494.7188 - acc: 0.3418 - val_loss: 494461.5625 - val_acc: 0.3619\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 410105.6875 - acc: 0.3556 - val_loss: 402530.5938 - val_acc: 0.3619\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 336286.6562 - acc: 0.3960 - val_loss: 336354.9688 - val_acc: 0.3714\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 279076.5625 - acc: 0.3981 - val_loss: 284363.3438 - val_acc: 0.3905\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 237269.6719 - acc: 0.4066 - val_loss: 242288.9531 - val_acc: 0.4000\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 203437.5000 - acc: 0.4130 - val_loss: 205275.6250 - val_acc: 0.4095\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 175989.2969 - acc: 0.4299 - val_loss: 174290.9531 - val_acc: 0.4381\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 153664.0781 - acc: 0.4406 - val_loss: 151622.1875 - val_acc: 0.4667\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 137078.8281 - acc: 0.4448 - val_loss: 133290.7656 - val_acc: 0.4571\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 124033.9375 - acc: 0.4448 - val_loss: 117023.0703 - val_acc: 0.4571\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 111120.9062 - acc: 0.4533 - val_loss: 103447.1250 - val_acc: 0.4762\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 100618.7109 - acc: 0.4501 - val_loss: 91654.6562 - val_acc: 0.4762\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 90735.8047 - acc: 0.4565 - val_loss: 82326.0938 - val_acc: 0.4857\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 82597.6875 - acc: 0.4597 - val_loss: 74148.8281 - val_acc: 0.4667\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 74863.0000 - acc: 0.4544 - val_loss: 67729.5547 - val_acc: 0.4571\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 67979.4453 - acc: 0.4607 - val_loss: 63144.6094 - val_acc: 0.4476\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 61874.3281 - acc: 0.4586 - val_loss: 59413.9844 - val_acc: 0.4667\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 56721.4531 - acc: 0.4448 - val_loss: 56015.5820 - val_acc: 0.4571\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 52640.0664 - acc: 0.4501 - val_loss: 53102.4805 - val_acc: 0.4571\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 48358.1758 - acc: 0.4416 - val_loss: 50143.0195 - val_acc: 0.4667\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 44404.2461 - acc: 0.4437 - val_loss: 47224.1992 - val_acc: 0.4762\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 40960.0312 - acc: 0.4469 - val_loss: 44413.5508 - val_acc: 0.4857\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 37963.0703 - acc: 0.4480 - val_loss: 42099.0664 - val_acc: 0.4762\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 35527.4336 - acc: 0.4427 - val_loss: 40359.7969 - val_acc: 0.4762\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 33381.2773 - acc: 0.4278 - val_loss: 39013.8867 - val_acc: 0.4857\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 31133.5293 - acc: 0.4416 - val_loss: 37706.7344 - val_acc: 0.4857\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 29337.7852 - acc: 0.4437 - val_loss: 36469.2422 - val_acc: 0.5048\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 27874.5547 - acc: 0.4607 - val_loss: 35453.7969 - val_acc: 0.5048\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 26397.6250 - acc: 0.4650 - val_loss: 34317.7148 - val_acc: 0.5048\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 25118.9375 - acc: 0.4607 - val_loss: 32947.1133 - val_acc: 0.5048\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 23891.6543 - acc: 0.4597 - val_loss: 31704.8086 - val_acc: 0.5048\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 22864.9844 - acc: 0.4703 - val_loss: 30629.5801 - val_acc: 0.4762\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 21816.9648 - acc: 0.4586 - val_loss: 29452.0996 - val_acc: 0.4571\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 20914.7637 - acc: 0.4671 - val_loss: 28375.7090 - val_acc: 0.4762\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 19989.3359 - acc: 0.4607 - val_loss: 27043.4902 - val_acc: 0.4762\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 19120.3965 - acc: 0.4820 - val_loss: 26028.6660 - val_acc: 0.4476\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 18259.5645 - acc: 0.4745 - val_loss: 24945.9961 - val_acc: 0.4762\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 17563.4531 - acc: 0.4798 - val_loss: 23829.1855 - val_acc: 0.4857\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 16819.9082 - acc: 0.4862 - val_loss: 22936.4551 - val_acc: 0.4762\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 16022.4707 - acc: 0.4660 - val_loss: 22157.6562 - val_acc: 0.4762\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 15231.8115 - acc: 0.4798 - val_loss: 21313.0859 - val_acc: 0.4667\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 14694.7812 - acc: 0.4766 - val_loss: 20514.2188 - val_acc: 0.4762\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 14022.3643 - acc: 0.4660 - val_loss: 19822.0469 - val_acc: 0.4667\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 13367.5400 - acc: 0.4788 - val_loss: 19286.1074 - val_acc: 0.4667\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 12735.8613 - acc: 0.4883 - val_loss: 18601.8770 - val_acc: 0.4762\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 12158.6680 - acc: 0.4851 - val_loss: 17836.6816 - val_acc: 0.4476\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 11585.4355 - acc: 0.4660 - val_loss: 17407.9512 - val_acc: 0.4667\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 11040.3672 - acc: 0.4873 - val_loss: 17191.4766 - val_acc: 0.4571\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 10551.1982 - acc: 0.4788 - val_loss: 17007.6621 - val_acc: 0.4667\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 10152.4229 - acc: 0.4873 - val_loss: 16560.7715 - val_acc: 0.4381\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 9699.8877 - acc: 0.4809 - val_loss: 16133.1592 - val_acc: 0.4476\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 9345.1152 - acc: 0.4703 - val_loss: 15551.9307 - val_acc: 0.4286\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 8938.0020 - acc: 0.4841 - val_loss: 15040.5557 - val_acc: 0.4667\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8540.1943 - acc: 0.4926 - val_loss: 14486.2705 - val_acc: 0.4571\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 8216.0879 - acc: 0.4820 - val_loss: 13935.7646 - val_acc: 0.4667\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 7882.8755 - acc: 0.4777 - val_loss: 13806.9141 - val_acc: 0.4667\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 7472.8271 - acc: 0.4777 - val_loss: 13500.5439 - val_acc: 0.4667\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 7243.6807 - acc: 0.4830 - val_loss: 13154.5605 - val_acc: 0.4476\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6971.1055 - acc: 0.4873 - val_loss: 12536.3164 - val_acc: 0.4667\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6684.1050 - acc: 0.4777 - val_loss: 12083.2988 - val_acc: 0.4762\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6403.8496 - acc: 0.4798 - val_loss: 11856.5830 - val_acc: 0.4667\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 6127.4771 - acc: 0.4788 - val_loss: 11457.5166 - val_acc: 0.4571\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5871.8516 - acc: 0.4894 - val_loss: 11011.7607 - val_acc: 0.4476\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5631.1230 - acc: 0.4841 - val_loss: 10970.2627 - val_acc: 0.4667\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 5420.2432 - acc: 0.4777 - val_loss: 10849.6670 - val_acc: 0.4476\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 5217.2026 - acc: 0.4904 - val_loss: 10595.9199 - val_acc: 0.4667\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 5020.8794 - acc: 0.4915 - val_loss: 10252.6162 - val_acc: 0.4762\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4825.7266 - acc: 0.4873 - val_loss: 9875.0283 - val_acc: 0.4667\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4632.1201 - acc: 0.4798 - val_loss: 9725.9678 - val_acc: 0.4476\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 4428.6040 - acc: 0.4947 - val_loss: 9647.3770 - val_acc: 0.4667\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 4229.4175 - acc: 0.4766 - val_loss: 9588.8857 - val_acc: 0.4667\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 4022.2493 - acc: 0.4862 - val_loss: 9380.8711 - val_acc: 0.4667\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3853.6035 - acc: 0.4841 - val_loss: 9196.5605 - val_acc: 0.4762\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 3636.0667 - acc: 0.4894 - val_loss: 9139.3369 - val_acc: 0.4762\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3486.4585 - acc: 0.4830 - val_loss: 8995.2998 - val_acc: 0.4286\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 3309.3220 - acc: 0.4766 - val_loss: 8767.7383 - val_acc: 0.4762\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 3147.2786 - acc: 0.4841 - val_loss: 8614.9512 - val_acc: 0.4762\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2993.1521 - acc: 0.4862 - val_loss: 8495.8896 - val_acc: 0.4762\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2860.4031 - acc: 0.4873 - val_loss: 8463.3115 - val_acc: 0.4857\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 2693.6274 - acc: 0.4915 - val_loss: 8488.3916 - val_acc: 0.4667\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2546.7585 - acc: 0.4820 - val_loss: 8470.1895 - val_acc: 0.4667\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 2379.4019 - acc: 0.4883 - val_loss: 8283.1865 - val_acc: 0.4762\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 2196.9268 - acc: 0.4873 - val_loss: 8089.0107 - val_acc: 0.4667\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 2057.6223 - acc: 0.4830 - val_loss: 7874.0986 - val_acc: 0.4381\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1953.1152 - acc: 0.4851 - val_loss: 7835.6006 - val_acc: 0.4762\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1894.1570 - acc: 0.4894 - val_loss: 7897.2124 - val_acc: 0.4667\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 1841.7800 - acc: 0.4926 - val_loss: 7829.2861 - val_acc: 0.4667\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1755.4893 - acc: 0.4862 - val_loss: 7712.0273 - val_acc: 0.4762\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 1675.1338 - acc: 0.4820 - val_loss: 7525.4868 - val_acc: 0.4762\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1605.7524 - acc: 0.4830 - val_loss: 7387.0952 - val_acc: 0.4762\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1512.1366 - acc: 0.4862 - val_loss: 7343.4229 - val_acc: 0.4857\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1437.4143 - acc: 0.4968 - val_loss: 7313.1787 - val_acc: 0.4857\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1365.3038 - acc: 0.4841 - val_loss: 7364.9341 - val_acc: 0.4762\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1273.5491 - acc: 0.4873 - val_loss: 7335.1416 - val_acc: 0.4762\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1210.2356 - acc: 0.4841 - val_loss: 7246.9053 - val_acc: 0.4667\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 1149.0486 - acc: 0.4915 - val_loss: 7128.0098 - val_acc: 0.4857\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1087.8577 - acc: 0.4883 - val_loss: 7094.7773 - val_acc: 0.4762\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1073.5039 - acc: 0.4936 - val_loss: 7026.5181 - val_acc: 0.4476\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 1000.3938 - acc: 0.4809 - val_loss: 7007.1528 - val_acc: 0.4857\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 940.8165 - acc: 0.4979 - val_loss: 7029.8291 - val_acc: 0.4762\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 901.5475 - acc: 0.4830 - val_loss: 6980.4731 - val_acc: 0.4667\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 849.2921 - acc: 0.4989 - val_loss: 6884.5645 - val_acc: 0.4762\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 814.7068 - acc: 0.4968 - val_loss: 6805.5381 - val_acc: 0.4476\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 745.8042 - acc: 0.4904 - val_loss: 6885.3145 - val_acc: 0.4762\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 724.9465 - acc: 0.4968 - val_loss: 6885.6758 - val_acc: 0.4476\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 687.6389 - acc: 0.4979 - val_loss: 6807.2808 - val_acc: 0.4667\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 645.0365 - acc: 0.4830 - val_loss: 6696.6587 - val_acc: 0.4762\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 599.1296 - acc: 0.5032 - val_loss: 6622.3267 - val_acc: 0.4762\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 590.2006 - acc: 0.4958 - val_loss: 6601.3794 - val_acc: 0.4762\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 555.7198 - acc: 0.4926 - val_loss: 6728.4839 - val_acc: 0.4667\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 527.3177 - acc: 0.4936 - val_loss: 6761.6895 - val_acc: 0.4762\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 521.0553 - acc: 0.5000 - val_loss: 6744.8179 - val_acc: 0.4476\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 489.8724 - acc: 0.4915 - val_loss: 6657.5356 - val_acc: 0.4857\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 482.5888 - acc: 0.4820 - val_loss: 6774.8896 - val_acc: 0.4857\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 460.6956 - acc: 0.5064 - val_loss: 6679.8525 - val_acc: 0.4857\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 441.5266 - acc: 0.4873 - val_loss: 6608.7871 - val_acc: 0.4952\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 431.8331 - acc: 0.5032 - val_loss: 6586.3145 - val_acc: 0.4857\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 412.3764 - acc: 0.5011 - val_loss: 6569.1924 - val_acc: 0.4762\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 390.4867 - acc: 0.4883 - val_loss: 6571.6357 - val_acc: 0.4762\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 377.9052 - acc: 0.4915 - val_loss: 6530.6655 - val_acc: 0.4762\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 381.0201 - acc: 0.5000 - val_loss: 6482.5552 - val_acc: 0.4571\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 376.1269 - acc: 0.5011 - val_loss: 6583.0645 - val_acc: 0.4857\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 366.6178 - acc: 0.4947 - val_loss: 6538.0522 - val_acc: 0.4762\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 357.9230 - acc: 0.4947 - val_loss: 6514.9722 - val_acc: 0.4857\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 334.9193 - acc: 0.5021 - val_loss: 6422.8931 - val_acc: 0.4857\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 316.5044 - acc: 0.4904 - val_loss: 6409.0361 - val_acc: 0.4952\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 305.0613 - acc: 0.5000 - val_loss: 6471.0488 - val_acc: 0.4762\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 315.3480 - acc: 0.4947 - val_loss: 6432.9487 - val_acc: 0.4857\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 306.6893 - acc: 0.4926 - val_loss: 6419.9727 - val_acc: 0.4762\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 295.4648 - acc: 0.4936 - val_loss: 6317.2607 - val_acc: 0.4857\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 315.3690 - acc: 0.4926 - val_loss: 6362.6929 - val_acc: 0.4857\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 304.9783 - acc: 0.4989 - val_loss: 6293.7700 - val_acc: 0.4857\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 285.6402 - acc: 0.4915 - val_loss: 6362.6411 - val_acc: 0.4857\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 312.8346 - acc: 0.5021 - val_loss: 6379.4502 - val_acc: 0.4857\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 308.7928 - acc: 0.4936 - val_loss: 6331.8335 - val_acc: 0.4857\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 297.8796 - acc: 0.4904 - val_loss: 6257.1577 - val_acc: 0.4952\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 262.2637 - acc: 0.4989 - val_loss: 6220.3477 - val_acc: 0.4952\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 266.1451 - acc: 0.4958 - val_loss: 6232.6284 - val_acc: 0.4857\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 275.4098 - acc: 0.5042 - val_loss: 6189.5850 - val_acc: 0.4857\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 262.5007 - acc: 0.4979 - val_loss: 6181.7881 - val_acc: 0.4952\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 250.0627 - acc: 0.4958 - val_loss: 6115.3340 - val_acc: 0.4952\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 261.1079 - acc: 0.4904 - val_loss: 6143.8096 - val_acc: 0.4381\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 247.3674 - acc: 0.4947 - val_loss: 6142.8994 - val_acc: 0.4952\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 260.7709 - acc: 0.4979 - val_loss: 6167.0806 - val_acc: 0.4762\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 248.3277 - acc: 0.5011 - val_loss: 6091.1104 - val_acc: 0.4952\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 230.1798 - acc: 0.5053 - val_loss: 6018.6494 - val_acc: 0.4857\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 247.1040 - acc: 0.4851 - val_loss: 5974.0591 - val_acc: 0.4952\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 241.3048 - acc: 0.4958 - val_loss: 6074.0127 - val_acc: 0.4857\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 233.4635 - acc: 0.4958 - val_loss: 6092.8662 - val_acc: 0.4857\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 259.3308 - acc: 0.5000 - val_loss: 6068.3672 - val_acc: 0.4857\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 256.5744 - acc: 0.4958 - val_loss: 6130.1050 - val_acc: 0.4476\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 240.7490 - acc: 0.4788 - val_loss: 6037.2935 - val_acc: 0.4857\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 226.2378 - acc: 0.5053 - val_loss: 5922.4419 - val_acc: 0.4952\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 228.7070 - acc: 0.5000 - val_loss: 5921.9272 - val_acc: 0.4857\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 211.3590 - acc: 0.4968 - val_loss: 5965.4058 - val_acc: 0.4857\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 205.1195 - acc: 0.4894 - val_loss: 5895.1392 - val_acc: 0.4952\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 0s 5ms/step - loss: 210.2204 - acc: 0.4947 - val_loss: 5920.6367 - val_acc: 0.4857\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 222.3415 - acc: 0.5021 - val_loss: 5895.2231 - val_acc: 0.4952\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 200.6482 - acc: 0.4947 - val_loss: 5883.4536 - val_acc: 0.4762\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 185.4432 - acc: 0.4947 - val_loss: 5827.6709 - val_acc: 0.4857\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 182.8641 - acc: 0.4894 - val_loss: 5831.5645 - val_acc: 0.4952\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 199.3485 - acc: 0.5064 - val_loss: 5836.0864 - val_acc: 0.4857\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 195.3693 - acc: 0.4841 - val_loss: 5805.2441 - val_acc: 0.4857\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 188.3515 - acc: 0.5032 - val_loss: 5737.7979 - val_acc: 0.4952\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 183.8843 - acc: 0.5021 - val_loss: 5827.3325 - val_acc: 0.4476\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 207.2128 - acc: 0.4936 - val_loss: 5802.2583 - val_acc: 0.4762\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 199.5201 - acc: 0.4915 - val_loss: 5755.4399 - val_acc: 0.4952\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 178.8410 - acc: 0.5032 - val_loss: 5672.7148 - val_acc: 0.4857\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 211.1618 - acc: 0.4968 - val_loss: 5600.4478 - val_acc: 0.4952\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 201.8475 - acc: 0.4915 - val_loss: 5690.9067 - val_acc: 0.4762\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 171.4767 - acc: 0.4947 - val_loss: 5720.5220 - val_acc: 0.4857\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 174.3550 - acc: 0.5021 - val_loss: 5636.3730 - val_acc: 0.4952\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 162.5277 - acc: 0.5000 - val_loss: 5593.3125 - val_acc: 0.4857\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 167.6490 - acc: 0.4862 - val_loss: 5635.5146 - val_acc: 0.4762\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 159.3978 - acc: 0.4958 - val_loss: 5601.1934 - val_acc: 0.4952\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 171.1933 - acc: 0.5042 - val_loss: 5590.8604 - val_acc: 0.4476\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 159.3649 - acc: 0.4926 - val_loss: 5562.7173 - val_acc: 0.4857\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 137.0472 - acc: 0.4947 - val_loss: 5570.1245 - val_acc: 0.4952\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 159.8026 - acc: 0.5032 - val_loss: 5627.6040 - val_acc: 0.4857\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 157.0583 - acc: 0.4936 - val_loss: 5512.2681 - val_acc: 0.4952\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 135.1040 - acc: 0.4936 - val_loss: 5502.8911 - val_acc: 0.4476\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 131.4909 - acc: 0.4926 - val_loss: 5528.1050 - val_acc: 0.4762\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 130.6522 - acc: 0.4894 - val_loss: 5466.1079 - val_acc: 0.4952\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 0s 6ms/step - loss: 120.7455 - acc: 0.5011 - val_loss: 5509.7979 - val_acc: 0.4952\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 130.7232 - acc: 0.4947 - val_loss: 5487.6963 - val_acc: 0.4857\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 119.8227 - acc: 0.4968 - val_loss: 5396.8213 - val_acc: 0.4857\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 145.5074 - acc: 0.4958 - val_loss: 5408.6689 - val_acc: 0.4667\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 132.3163 - acc: 0.4883 - val_loss: 5501.0674 - val_acc: 0.4857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pG1O5ymTan4s"
      },
      "source": [
        "## 7) 觀察訓練結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFUTBafCan4u"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "history_dict.keys()\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs_ = range(1,len(acc)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5PL5GAwan4x"
      },
      "source": [
        "plt.plot(epochs_ , loss , label = 'training loss')\n",
        "plt.plot(epochs_ , val_loss , label = 'val los')\n",
        "plt.title('training and val loss')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ketuv_Bvan43"
      },
      "source": [
        "plt.clf()\n",
        "plt.plot(epochs_ , acc , label='train accuracy')\n",
        "plt.plot(epochs_ , val_acc , label = 'val accuracy')\n",
        "plt.title('train and val acc')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('acc')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR5QIun7an47"
      },
      "source": [
        "## 8) 測試"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdG9q4M9an47"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "label=np.argmax(y,axis=1)\n",
        "pred =  np.argmax(model.predict(X), axis=1)\n",
        "# print(pred.shape)\n",
        "print(accuracy_score(label, pred))\n",
        "# print(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNWE7Fe8uBzn"
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNxXer-qOlwj"
      },
      "source": [
        "## 9) 檢查特徵重要性\n",
        "> https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html\n",
        "> https://www.mdeditor.tw/pl/pgi5/zh-tw\n",
        "\n",
        "> 針對BlackBox模型或非sklearn模型，使用排列重要性方法\n",
        "\n",
        "\n",
        "> 捨棄重要性低、增加損失的features特徵，重新建模訓練。\n",
        "\n",
        "\n",
        "> \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-t6pvZman4_"
      },
      "source": [
        "# import numpy as np\n",
        "from eli5.permutation_importance import get_score_importances\n",
        "\n",
        "# ... load data, define score function\n",
        "def score(X, y):\n",
        "    y_pred = np.argmax(model.predict(X), axis=1)\n",
        "    return accuracy_score(y, y_pred)\n",
        "\n",
        "lab=np.argmax(y_train,axis=1)\n",
        "base_score, score_decreases = get_score_importances(score, X_train.values, lab)\n",
        "feature_importances = np.mean(score_decreases, axis=0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz2cPz1KQtQy"
      },
      "source": [
        "# print(feature_importances)\n",
        "feature_importance_dict = {}\n",
        "for i, feature_name in enumerate(X.columns.values.tolist()) :\n",
        "\tfeature_importance_dict[feature_name]=feature_importances[i]\n",
        "\n",
        "# print(dict(sorted(feature_importance_dict.items(), key=lambda x:x[1],reverse=True)[:5]))\n",
        "sorted_fi = dict(sorted(feature_importance_dict.items(), key=lambda x:x[1],reverse=True))\n",
        "for name,i in sorted_fi.items():\n",
        "  print(name, i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}